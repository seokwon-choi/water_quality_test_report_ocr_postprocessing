{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR_final_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZUM-hS1tWBM"
      },
      "source": [
        "- 밑에 함수 선언부터 해야 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOVrdZtsBynD"
      },
      "source": [
        "## - OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcASpICLtWBT"
      },
      "source": [
        "dirname = 'ocr_sample'\n",
        "dir_path = 'C:/Users/폴더까지경로/' + dirname + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBR-w6ALtWBU"
      },
      "source": [
        "ocr_image(dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY-BrbT0BynE"
      },
      "source": [
        "## - txtfile 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwK2iji0tWBV"
      },
      "source": [
        "# 폴더 내의 txt 파일을 모두 읽어 리스트로 저장\n",
        "data_list = []\n",
        "for txtfile in glob.iglob(dir_path + \"*.txt\") :\n",
        "    with open(txtfile, \"r\", encoding='utf-8') as file :\n",
        "        read_txt = file.readlines()\n",
        "        read_txt = np.char.strip(read_txt)\n",
        "    data_list.append(read_txt)\n",
        "\n",
        "data_list = np.array(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMDz7mcatWBW"
      },
      "source": [
        "# 파싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Bf9-6QlhtWBX"
      },
      "source": [
        "# 파싱한 결과를 DataFrame으로 저장\n",
        "parse_info = parsing(data_list)\n",
        "test_info = pd.DataFrame(parse_info, columns=['place', 'date', 'company', 'judgment'])\n",
        "\n",
        "test_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_TjoHicbtWBY"
      },
      "source": [
        "# 검사항목 파싱 결과 DataFrame들을 리스트로 저장\n",
        "d = test_info['date'].values.tolist()[0]\n",
        "ocr = [chemi_parsing(dt, d) for dt in data_list]\n",
        "chem, use = [tb[0] for _,tb in enumerate(ocr)], [tb[1] for _,tb in enumerate(ocr)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQb6ut2ZtWBZ"
      },
      "source": [
        "chem[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Ksl77_tWBa"
      },
      "source": [
        "# 후처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IHMjACWutWBa"
      },
      "source": [
        "# 장소 후처리 결과로 DataFrame 업데이트\n",
        "place = np.array(test_info.place.tolist())\n",
        "place = pd.DataFrame({'place':np.vectorize(postp_address)(place)})\n",
        "\n",
        "test_info.update(place)\n",
        "\n",
        "test_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLwFbnjItWBb"
      },
      "source": [
        "get_map()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCO0B1tctWBb"
      },
      "source": [
        "# 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ra-elCdBym3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "# 파일 읽기\n",
        "import io\n",
        "import os\n",
        "import glob\n",
        "# 단어 비교\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "from symspellpy.helpers import DictIO\n",
        "from jamo import h2j, j2hcj\n",
        "# 지도\n",
        "from google.cloud import vision\n",
        "import googlemaps\n",
        "import folium\n",
        "from folium import plugins\n",
        "from owslib.wms import WebMapService\n",
        "from math import sin, cos, sqrt,atan2, radians\n",
        "import webbrowser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmIVOHMZBym9"
      },
      "source": [
        "# 데이터셋 - 전국 주소 / 업체명 / 시료명에 따른 수질검사기준 파일이름 / 오염원 주소\n",
        "address_dataset = pd.read_csv('address.csv')\n",
        "col = list(address_dataset.columns)\n",
        "company_dataset = pd.read_csv('company.csv')\n",
        "sample_dataset = pd.read_csv('sample.csv')\n",
        "pollution = pd.read_csv('pollution_address.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9pVd0IXBym-"
      },
      "source": [
        "# 입력단어와 후보단어의 해밍거리 계산\n",
        "def Hamming(inp, suggest, opt):    \n",
        "    inp_l, sug_l = list(inp), list(suggest)\n",
        "    # 길이 동일한 경우 바로 계산\n",
        "    if len(inp) == len(suggest) :\n",
        "        hamming_val = np.vectorize(Hamming_value)(np.array(inp_l), np.array(sug_l), opt).sum()\n",
        "        return (hamming_val, 0) if opt is 2 else hamming_val\n",
        "    \n",
        "    # 길이 차이 나는 경우 : (나트륨-니트) -> (나트-니트)(트륨-니트) 비교\n",
        "    hamming = []\n",
        "    small, big = small_big(inp, suggest)\n",
        "    dist = big - small\n",
        "    for i in range(dist+1) :\n",
        "        if small is len(inp) :\n",
        "            hamming_val = np.vectorize(Hamming_value)(np.array(inp_l), np.array(sug_l[i:i+small]), opt)\n",
        "        else :\n",
        "            hamming_val = np.vectorize(Hamming_value)(np.array(inp_l[i:i+small]), np.array(sug_l), opt)\n",
        "        \n",
        "        hamming_val = hamming_val.sum()\n",
        "        # 길이 차이에 대한 가중치 부여\n",
        "        if opt == 0 :\n",
        "            hamming_val += dist * 3\n",
        "        elif opt == 3 :\n",
        "            hamming_val += dist\n",
        "        hamming.append(hamming_val)\n",
        "        \n",
        "    # 파싱 중 사용될 경우 인덱스까지 반환\n",
        "    if opt == 2 :\n",
        "        hamming = np.array(hamming)\n",
        "        index = np.where(hamming == hamming.min())\n",
        "        return hamming.min(), index[0][0]\n",
        "    \n",
        "    else :\n",
        "        hamming.sort()\n",
        "        return hamming[0]\n",
        "\n",
        "    \n",
        "# 각 글자의 자모음 비교\n",
        "def Hamming_value(input_phone, suggest_phone, opt) :\n",
        "    value = 0\n",
        "    # 글자의 자모음 분리\n",
        "    input_sylla = j2hcj(h2j(input_phone))\n",
        "    suggest_sylla = j2hcj(h2j(suggest_phone))\n",
        "    \n",
        "    if len(input_sylla) == len(suggest_sylla) :\n",
        "        inp, sug = list(input_sylla), list(suggest_sylla)\n",
        "        cnt_sylla = len(input_sylla)\n",
        "    else :\n",
        "        small, big = small_big(input_sylla, suggest_sylla)\n",
        "        value += big - small\n",
        "        \n",
        "        if small is len(input_sylla) :\n",
        "            inp, sug = list(input_sylla), list(suggest_sylla)[:small]\n",
        "        else :\n",
        "            inp, sug = list(input_sylla)[:small], list(suggest_sylla)\n",
        "        cnt_sylla = small\n",
        "        \n",
        "    inp, sug = np.array(inp), np.array(sug)\n",
        "    comp = inp == sug\n",
        "    c = 3 if opt == 3 else 1\n",
        "    result = np.vectorize(lambda a: -c if a is True else 1)(comp)\n",
        "    value += result.sum()\n",
        "        \n",
        "    return value\n",
        "\n",
        "# 문자열 길이 비교\n",
        "def small_big(a, b) :\n",
        "    small = len(a) < len(b) and len(a) or len(b)\n",
        "    big = len(a) > len(b) and len(a) or len(b)\n",
        "    return small, big"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rnLP7XxBym-"
      },
      "source": [
        "# 후보 중 입력 단어와 가장 비슷한 단어 반환\n",
        "def find_similar(input_val, cand_list, maxedit=3) :\n",
        "    maxeditdist = len(input_val)-1 if len(input_val) < maxedit else maxedit\n",
        "    if maxedit == 4 : # 검사항목 파싱용\n",
        "        # 해당 단어들이 나오면 비슷한 단어 안찾고 패스\n",
        "        exceptions = ['기준', '검사', '채수', '의뢰', '시료', '번호', '접수', '적합', '인허가용']\n",
        "        filt = np.vectorize(lambda a: a in input_val)(exceptions)\n",
        "        if (input_val.lower() != input_val.upper()) or (filt.any()) :\n",
        "            return None\n",
        "    # SymSpell - find candidate\n",
        "    cand_dict = {cand: 1 for cand in cand_list}\n",
        "    sym_spell = SymSpell(max_dictionary_edit_distance=maxeditdist)\n",
        "    dict_stream = DictIO(cand_dict)\n",
        "    sym_spell.load_dictionary_stream(dict_stream, 0, 1)\n",
        "    \n",
        "    suggestions = sym_spell.lookup(input_val, Verbosity.CLOSEST, max_edit_distance=maxeditdist)\n",
        "    suggestion_list = [suggestion.term for suggestion in suggestions]\n",
        "    \n",
        "    list_made = 0\n",
        "    if not suggestion_list :\n",
        "        # 검사항목 파싱 시 symspell에서 리스트 안만들어지면 그냥 끝냄\n",
        "        if maxedit == 4 :\n",
        "            return None\n",
        "        \n",
        "        list_made = 1\n",
        "        cand = np.array(cand_list)\n",
        "        inp_v = list(input_val)\n",
        "        suggest_index = list(map(lambda a: np.where(np.char.find(cand, a)>=0), inp_v))\n",
        "        suggest_index = np.concatenate(suggest_index, axis=None).tolist()\n",
        "        suggestion_list = cand[suggest_index]\n",
        "        suggestion_list = list(set(suggestion_list.tolist()))\n",
        "    \n",
        "    if len(suggestion_list) == 1 :\n",
        "        return suggestion_list[0]\n",
        "    else :\n",
        "        if not suggestion_list :\n",
        "            return None\n",
        "        if maxedit == 4 and len(suggestion_list) > 5 :\n",
        "            return None\n",
        "        hamming_list = [np.vectorize(lambda a: Hamming(input_val, a, list_made))(suggestion_list)]\n",
        "    \n",
        "        minv = np.argmin(hamming_list)\n",
        "        return suggestion_list[minv]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhTHpxu2tWBd"
      },
      "source": [
        "# substring 찾기\n",
        "def find_substr(data, substr, ver) :\n",
        "    exist = np.where(np.core.defchararray.find(data, substr) >= 0)[0]\n",
        "    if ver is 1 :     # 채수장소 카테고리\n",
        "        res = exist[0] if data[exist].size > 0 else -1\n",
        "    elif ver is 2 :   # 시료명\n",
        "        res = substr if data[exist].size > 0 else None\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIAV4pHHBym_"
      },
      "source": [
        "# 채수장소"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo1zMNNNGi4M"
      },
      "source": [
        "def isEnter(data, index):\n",
        "    res = data[index+1] if len(data[index]) < 7 else data[index]\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngRg7JNUtWBe"
      },
      "source": [
        "def find_place(data_orig):\n",
        "    data = np.copy(data_orig)\n",
        "    # 카테고리 찾기\n",
        "    category = np.array(['채수장소', '시료채취주소', '지하수개발이용시설위치', '지하수개발·이용시설위치'])\n",
        "    fnd = np.vectorize(lambda a: find_substr(data, a, 1))(category)\n",
        "    \n",
        "    if fnd[fnd!=-1].size > 0 :\n",
        "        place_category = category[fnd != -1][0]\n",
        "        index = fnd[fnd != -1][0]\n",
        "        start = np.where(np.core.defchararray.find(data[index], place_category) != -1)[0][0]\n",
        "        data[index] = data[index][start+len(place_category):]\n",
        "        content = isEnter(data, index)\n",
        "        return content\n",
        "    \n",
        "    modified_data = np.core.defchararray.replace(data, ' ', '')\n",
        "    modified_data = np.vectorize(lambda a : ' '+a)(modified_data)\n",
        "    \n",
        "    Hamming_place, index = [], []\n",
        "    for cat in category:\n",
        "        hammed = np.vectorize(lambda a: Hamming(cat, a, 2))(modified_data)\n",
        "        line = np.argmin(hammed[0])\n",
        "        Hamming_place.append(np.min(hammed[0])) \n",
        "        index.append([line, hammed[1][line]])\n",
        "   \n",
        "    most_similar_category = np.argmin(Hamming_place)\n",
        "    category, index = category[most_similar_category], index[most_similar_category]\n",
        "    line, word = index[0], index[1]\n",
        "    \n",
        "    categ_last = len(modified_data[line]) - 1 if len(modified_data[line]) <= word+len(category) else word+len(category)-1\n",
        "    categ_last = modified_data[categ_last]\n",
        "    last_idx = data[line].find(category_last)\n",
        "\n",
        "    last_idx += 2 if ((last_idx != len(data[line])-1) and (data[line][last_idx+1] == ' ')) else 0\n",
        "\n",
        "    data[line] = data[line][last_idx:]\n",
        "    content = isEnter(data, line)\n",
        "    \n",
        "    return content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-mGiZEkBym_"
      },
      "source": [
        "def postp_address(placestr) :\n",
        "    data = address_dataset\n",
        "    \n",
        "    input_p = placestr.split()\n",
        "    not_found_list = []\n",
        "    \n",
        "    for num in range(5) :\n",
        "        if data[col[num]].isnull().values.all() :\n",
        "            break\n",
        "            \n",
        "        not_found = data[data[col[num]].isin([input_p[num]])].empty\n",
        "        if not_found :\n",
        "            not_found_list.append(num)\n",
        "            continue\n",
        "            \n",
        "        data = data[data[col[num]] == input_p[num]]\n",
        "        \n",
        "    if len(data) != 1 :\n",
        "        found = find_best(data, input_p, not_found_list)\n",
        "        data = found[0]\n",
        "        if found[2] is 1 :\n",
        "            num = found[1] \n",
        "    end_ind = np.where(np.array(input_p)=='의뢰자명')[0][0] if '의뢰자명' in input_p else len(input_p)\n",
        "    place = ' '.join([data.iloc[0][i] for i in range(num)]) + \" \" + ' '.join(input_p[num:end_ind])\n",
        "    return place"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHw-SbaIBynA"
      },
      "source": [
        "def find_best(df, target, target_num) :\n",
        "    need_find = target_num\n",
        "    df_tmp = df\n",
        "    \n",
        "    before = np.array(['경남', '경북', '전남', '전북', '충남', '충북'])\n",
        "    after = np.array(['경상남도', '경상북도', '전라남도', '전라북도', '충청남도', '충청북도'])\n",
        "    \n",
        "    if 0 in need_find :\n",
        "        ind = np.where(before == target[0])[0]\n",
        "        if ind.size > 0 :\n",
        "            target[0] = after[ind[0]]\n",
        "        \n",
        "    onway = 0\n",
        "    for i in need_find :\n",
        "        if df_tmp[col[i]].isnull().values.all() :\n",
        "            # 전부 nan만 나오게 되면 상세주소 시작함\n",
        "            onway = 1\n",
        "            ind = i\n",
        "            break\n",
        "                \n",
        "        candidate = list(set(df_tmp[col[i]].values))\n",
        "        if len(candidate) == 1 :\n",
        "            df_tmp = df_tmp[df_tmp[col[i]] == candidate[0]]\n",
        "        else :\n",
        "            sim = find_similar(target[i], candidate)\n",
        "            df_tmp = df_tmp[df_tmp[col[i]] == sim]\n",
        "        ind = i\n",
        "            \n",
        "    res = (df_tmp, ind, onway)\n",
        "            \n",
        "    if df_tmp.empty :\n",
        "        res = find_best(df, target, reversed(target_num))\n",
        "        \n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYgDAWFgBynA"
      },
      "source": [
        "# 판정 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7phoVsQBynA"
      },
      "source": [
        "def find_judgement(data) :\n",
        "    \n",
        "    c, i = '적합', '부적합'\n",
        "    data = np.core.defchararray.replace(data, ' ', '') \n",
        "    data = np.delete(data, np.where(data == ''))\n",
        "    \n",
        "    c_data = np.vectorize(Hamming)(data, c, 3)\n",
        "    i_data = np.vectorize(Hamming)(data, i, 3)\n",
        "        \n",
        "    judg, H = np.where(c_data < i_data, c, i), np.where(c_data < i_data, c_data, i_data)\n",
        "    judg_index = np.argmin(H)\n",
        "    judgement = judg[judg_index]\n",
        "\n",
        "    return judgement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jbqpy_GBynB"
      },
      "source": [
        "# 시료명"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAD86JR8BynB"
      },
      "source": [
        "def find_sample(data, date):\n",
        "    #1. 시료명 선택\n",
        "    sample = sample_dataset['시료명'].values.tolist()\n",
        "    use = np.vectorize(lambda a: find_substr(data, a, 2))(sample)\n",
        "    use = use[use != None]\n",
        "    \n",
        "    if use.size > 0 :\n",
        "        use = use[0]\n",
        "    else :\n",
        "        hamming = np.vectorize(lambda a: Hamming(a, data, 0))(sample)\n",
        "        use = sample[np.argmin(hamming)]\n",
        "        \n",
        "    #2. dicname 조회\n",
        "    year, month = int(date[:4]), int(date[6:8])\n",
        "    \n",
        "    if year<2018 and month<7 :\n",
        "        dic_name = sample_dataset[sample_dataset['시료명']== use]['2018 개정 전'].values[0]\n",
        "    else :\n",
        "        dic_name = sample_dataset[sample_dataset['시료명']== use]['2018 개정 후'].values[0]\n",
        "\n",
        "    return use, dic_name+'.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0drrCUtRBynB"
      },
      "source": [
        "# 채수일자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnMoXteEBynB"
      },
      "source": [
        "def find_date(data):\n",
        "    # 201X년 XX월 XX일의 문자열 검색\n",
        "    mtch = np.vectorize(lambda a: re.search('201\\d{1}년 \\d{2}월 \\d{2}일', a))(data)\n",
        "    mtch = np.delete(mtch, np.where(mtch==None))\n",
        "    \n",
        "    if mtch.size > 0 :\n",
        "        test_date = np.vectorize(lambda a: a.group(0))(mtch)\n",
        "        final_date = test_date[0] if test_date.size == 1 else cmp_date(test_date)\n",
        "        return final_date\n",
        "    \n",
        "    mtch = np.vectorize(lambda a: re.search('201\\d{1}-\\d{2}-\\d{2}', a))(data)\n",
        "    mtch = np.delete(mtch, np.where(mtch==None))\n",
        "    if mtch.size > 0 :\n",
        "        test_date = np.vectorize(lambda a: a.group(0))(mtch)\n",
        "        final_date = cmp_date(test_date)\n",
        "        return final_date\n",
        "        \n",
        "    dt = np.vectorize(lambda a: re.search('201\\d{1}', a))(data)\n",
        "    index = np.where(dt != None)\n",
        "    mtch, mtch_str = dt[index], data[index]\n",
        "    datestr = np.vectorize(lambda a, b: a[b.start():])(mtch_str, mtch)\n",
        "    final_date = cmp_date(datestr)\n",
        "        \n",
        "    return final_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4KACZXEtWBh"
      },
      "source": [
        "def cmp_date(date_str):\n",
        "    # 201X년 추출\n",
        "    year = np.vectorize(lambda a: re.search('201\\d{1}', a))(date_str)\n",
        "    \n",
        "    # XX월 추출\n",
        "    month = np.vectorize(lambda a: re.search('\\d{2}월', a))(date_str)\n",
        "    # - XX월 없으면 숫자 XX 찾음\n",
        "    condm = month == None\n",
        "    if np.any(condm) :\n",
        "        month[condm] = np.vectorize(lambda a: re.search(\"\\d{2}\", a[4:]))(date_str[condm])\n",
        "        condm = month == None\n",
        "    # - 안찾아지면 날짜 없는 것\n",
        "    if np.all(condm) :\n",
        "        return None\n",
        "    if np.any(condm) :\n",
        "        delete_str = np.where(condm)\n",
        "        date_str = np.delete(date_str, delete_str)\n",
        "        year, month = np.delete(year, delete_str), np.delete(month, delete_str)   \n",
        "        \n",
        "    # XX일 추출\n",
        "    day = np.vectorize(lambda a: re.search('\\d{2}일', a))(date_str.tolist())\n",
        "    # - XX일 없으면 숫자 XX 찾음\n",
        "    condd = day == None\n",
        "    if np.any(condd) :\n",
        "        day[condd] = np.vectorize(lambda a, b: re.search(\"\\d{2}\", a[4+b.end():]))(date_str[condd], month[condd])\n",
        "        condd = day == None\n",
        "    if np.all(condd) :\n",
        "        return None\n",
        "    if np.any(condd) :\n",
        "        delete_str = np.where(condd)\n",
        "        date_str, year = np.delete(date_str, delete_str), np.delete(year, delete_str)\n",
        "        month, day = np.delete(month, delete_str), np.delete(day, delete_str)\n",
        "        \n",
        "    year_str = np.vectorize(lambda a: a.group(0))(year)    \n",
        "    month_str = np.vectorize(lambda a: a.group(0))(month)\n",
        "    day_str = np.vectorize(lambda a: a.group(0))(day)\n",
        "    \n",
        "    # 날짜가 1개 이상이면 비교해서 가장 과거의 날짜로 선택\n",
        "    if date_str.size > 1 :\n",
        "        cm = cmp(month_str)\n",
        "        month_str = month_str[cm]\n",
        "        \n",
        "        day_str = day_str[cm]\n",
        "        cd = cmp(day_str)\n",
        "        day_str = day_str[cd]\n",
        "        \n",
        "    test_date = year_str[0] + '년'\n",
        "    test_date += ' '+month_str[0] if len(month_str[0]) > 2 else ' '+month_str[0]+'월'\n",
        "    test_date += ' '+day_str[0] if len(day_str[0]) > 2 else ' '+day_str[0]+'일'\n",
        "        \n",
        "    return test_date\n",
        "\n",
        "def cmp(dts) :\n",
        "    # 각 match객체를 숫자로 변경한 후 최소값이 되는 문자열의 위치 반환\n",
        "    tonum = np.vectorize(lambda a: int(''.join(filter(str.isdigit, a))))(dts)\n",
        "    return np.where(tonum == tonum.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSUKhgNBynC"
      },
      "source": [
        "# 검사항목"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoBvey5nBynC"
      },
      "source": [
        "def chemi_parsing(data, date):\n",
        "    data = np.array(data)\n",
        "    use, dic_name = find_sample(data, date)\n",
        "    \n",
        "    start_index = np.union1d(np.where(data == '준'), np.where(data == '과'))\n",
        "    start_index = np.union1d(start_index, np.where(data == '검사기준'))\n",
        "    start_index = np.union1d(start_index, np.where(data == '검사항목'))\n",
        "    start = start_index[0]+1 if start_index.size > 0 else 0\n",
        "    \n",
        "    graph = data[start:]\n",
        "    \n",
        "    f = open(dic_name, 'r', encoding='UTF8')\n",
        "    f_dic = f.readlines()\n",
        "    f.close()\n",
        "    \n",
        "    dic_standard = {}\n",
        "    for i in f_dic:\n",
        "        key = i.split()\n",
        "        dic_standard[key[0]] = key[1]\n",
        "        \n",
        "    # [화학물]  [화학물+불검출]\n",
        "    dic_chemi = list(dic_standard.keys())\n",
        "    dic_plus = dic_chemi.copy()\n",
        "    dic_plus.extend(['불검출', '검출'])\n",
        "    \n",
        "    # 숫자, '/L' 포함 문자열, 화학물 리스트에 있는 단어 제외한 전체 대상으로 symspell 돌림\n",
        "    cond1 = np.vectorize(lambda a: a.replace('.', '').replace(',','').isdigit())(graph)\n",
        "    cond2 = np.char.find(graph, '/L') != -1\n",
        "    cond3 = np.vectorize(lambda a: a in dic_plus)(graph)\n",
        "    cond = np.logical_or(cond1, cond2)\n",
        "    cond = np.logical_or(cond, cond3)\n",
        "    \n",
        "    need_change = graph[cond == False]\n",
        "    ind_tmp = np.where(cond == False)\n",
        "    graph[cond == False] = np.vectorize(lambda a: find_similar(a.replace('.',','), dic_plus, 4))(need_change)\n",
        "    \n",
        "    chemi = graph[np.vectorize(lambda a: a in dic_chemi)(graph)]\n",
        "    chem, ind = np.unique(chemi, return_index=True)\n",
        "    chemi = chem[ind.argsort()]\n",
        "    \n",
        "    result_index = np.union1d(np.where(cond1 == True), np.where(graph == '불검출'))\n",
        "    result_index = np.union1d(result_index, np.where(graph == '없음'))\n",
        "    result = graph[result_index]\n",
        "    \n",
        "    standard = np.vectorize(lambda a: dic_standard[a])(chemi)    \n",
        "    # - 결과값이 덜 인식된 경우 ; NaN으로 채움\n",
        "    if chemi.shape > result.shape :\n",
        "        nans = np.empty((chemi.shape[0] - result.shape[0],))\n",
        "        nans.fill(np.nan)\n",
        "        result = np.concatenate((result, nans))\n",
        "    # - 결과값이 더 인식된 경우 ; 잘라냄\n",
        "    elif chemi.shape < result.shape :\n",
        "        result = result[:chemi.shape[0]]\n",
        "        \n",
        "    ocr = pd.DataFrame(np.array([chemi, standard, result]).T, columns=['검사항목', '기준', '결과'])\n",
        "    \n",
        "    return ocr, use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3H5vXp6BynD"
      },
      "source": [
        "def parsing(data_list):\n",
        "\n",
        "    return_list = []\n",
        "    for data in data_list :\n",
        "        place = find_place(data)\n",
        "        place = place.replace('|', '')\n",
        "        date = find_date(data)\n",
        "        test_result = find_judgement(data)\n",
        "        \n",
        "        # find company (업체명)\n",
        "        company_data = company_dataset\n",
        "        pattern = company_data['패턴'].values.tolist()\n",
        "        \n",
        "        mtch = [patt for patt in pattern for txt in data if patt in txt.replace(' ', '')]\n",
        "        found_pattern = list(set(mtch))\n",
        "        \n",
        "        company = company_data[company_data['패턴'].isin(found_pattern)]\n",
        "        company = list(set(company['업체명'].values))[0]\n",
        "        \n",
        "        return_list.append([place, date, company, test_result])\n",
        "\n",
        "    return return_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axu8-sk8tWBi"
      },
      "source": [
        "# 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCjcWsspBynE"
      },
      "source": [
        "def ocr_image(dir_path):\n",
        "    json_path = 'C:/ocr json 파일까지 경로'\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = json_path\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "\n",
        "    # 폴더명 입력시 폴더 내의 이미지 이름과 같은 이름으로 txt 파일 생성\n",
        "    #dirname = input(\"샘플 이미지가 들어있는 폴더명을 입력하세요 : \")\n",
        "\n",
        "    for file in glob.glob(dir_path + \"*.jpg\") :\n",
        "        img_name = (os.path.basename(file))\n",
        "        txt_name = img_name.replace('.jpg', '.txt')\n",
        "\n",
        "        f = open(dir_path+txt_name, 'w', encoding = 'utf-8')\n",
        "\n",
        "        file_name = os.path.abspath(file)\n",
        "\n",
        "        with io.open(file_name, 'rb') as image_file :\n",
        "            content = image_file.read()\n",
        "\n",
        "        image = vision.Image(content=content)\n",
        "        response = client.document_text_detection(image = image)\n",
        "\n",
        "        f.write(response.text_annotations[0].description)\n",
        "        f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfCeYSHSBynF"
      },
      "source": [
        "# 지도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7DHqPfWBynG"
      },
      "source": [
        "g_maps = googlemaps.Client(key='google maps key값')\n",
        "def getLatLng(address):\n",
        "    result = \"\"\n",
        "    geocode_result = g_maps.geocode(address)\n",
        "    \n",
        "    lat = geocode_result[0][\"geometry\"][\"location\"][\"lat\"]\n",
        "    lng = geocode_result[0][\"geometry\"][\"location\"][\"lng\"]\n",
        "    \n",
        "    return [lat, lng]\n",
        "\n",
        "# 두 장소 사이 거리 구하기 (단위 km)\n",
        "def get_distance(lat1, lng1, lat2, lng2):\n",
        "    R = 6373.0\n",
        "    \n",
        "    lat1, lng1 = radians(lat1), radians(lng1)\n",
        "    lat2, lng2 = radians(lat2), radians(lng2)\n",
        "    \n",
        "    dlon = lng2 - lng1\n",
        "    dlat = lat2 - lat1\n",
        "    \n",
        "    a = sin(dlat/2)**2+cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
        "    c = 2*atan2(sqrt(a), sqrt(1-a))\n",
        "    \n",
        "    return R*c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "iT5c0strtWBj"
      },
      "source": [
        "def get_map():\n",
        "    address = [getLatLng(place) for place in test_info.place.tolist()]\n",
        "    cent = [35.95, 128.25]\n",
        "    distance = float(input(\"반경 입력 (단위:m) : \"))\n",
        "    m = folium.Map(location = cent, zoom_start = 8)\n",
        "\n",
        "    classes = (\"table table-striped table-hover table-condensed table-responsive\")\n",
        "    colours = {'도축업장': 'red', '축산농장': '#ff751a', '폐기물처리장': '#ffcc00',  '골프장': '#33cc33', '주유소': '#33ccff', \n",
        "                '공공하수처리시설': 'blue', '지하수정화시설': '#b366ff', '기타수질오염원설치시설': '#ff4dd2', '공장': 'black'}\n",
        "    legend_html = \"\"\"<div style=\"position:fixed; bottom:10px; left:10px; width:155px; height:175px; \n",
        "                        border:2px solid black; z-index:9999; background-color:white; opacity: .75;\n",
        "                        font-size:12px;\">&nbsp;<b>\"\"\"+'오염원'+\"\"\":</b><br>\"\"\"\n",
        "\n",
        "    #setting subgroups\n",
        "    con = folium.FeatureGroup(name='적합')\n",
        "    incon = folium.FeatureGroup(name='부적합')\n",
        "    pol = plugins.FeatureGroupSubGroup(incon, name='오염원', show=False)\n",
        "    m.add_child(con)\n",
        "    m.add_child(incon)\n",
        "    m.add_child(pol)\n",
        "\n",
        "    # colour setting legend\n",
        "    for key, value in colours.items():\n",
        "        legend_html = legend_html+\"\"\"&nbsp;<i class=\"fa fa-circle \n",
        "                                    fa-1x\" style=\"color:\"\"\"+value+\"\"\"\">\n",
        "                                    </i>&nbsp;\"\"\"+key+\"\"\"<br>\"\"\"\n",
        "    legend_html += \"\"\"</div>\"\"\"\n",
        "    m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "    for i, addr in enumerate(address):\n",
        "        html = f\"\"\"<p><strong>채수장소 : </strong>{test_info.place[i]}</br>\n",
        "                <strong>채수일자 : </strong>{test_info.date[i]}</br>\n",
        "                <strong>업체명 : </strong>{test_info.company[i]}</br>\n",
        "                <strong>판정 : </strong>{test_info.judgment[i]}</br>\n",
        "                <strong>시료명 : </strong>{use[i]}</p>\"\"\"\n",
        "\n",
        "        popup = html + chem[i].to_html(classes=classes)\n",
        "        popup = folium.Popup(popup, max_width=500)\n",
        "\n",
        "        if test_info.judgment[i] == '적합':\n",
        "            folium.Marker(addr, popup=popup,tooltip=\"결과확인\", icon=folium.Icon(color='blue', icon='ok')).add_to(con)\n",
        "        else:\n",
        "            folium.Marker(addr, popup=popup,tooltip=\"결과확인\", icon=folium.Icon(color='red', icon='remove')).add_to(incon)\n",
        "            folium.Circle(addr, radius=3000, popup=None, color=\"black\").add_to(pol)\n",
        "            for j in pollution.index :\n",
        "                loc = pollution.loc[j, '좌표'].strip('][').split(', ')\n",
        "                ch0 = float(loc[0])   #좌표가 string형이라 float형으로 바꿔준다.\n",
        "                ch1 = float(loc[1])\n",
        "\n",
        "                dist = get_distance(addr[0], addr[1], ch0, ch1)\n",
        "\n",
        "                if dist <= (distance/1000) : #단위 km\n",
        "                    colour = colours[pollution.loc[j, '분류']]\n",
        "                    icon = plugins.BeautifyIcon(icon=\"exclamation-sign\", text_color=colour)\n",
        "                    folium.Circle(\n",
        "                        location = (loc[0], loc[1]),\n",
        "                        tooltip = pollution.loc[j, '사업장명'],\n",
        "                        radius=40, color=colour, fill_color=colour, fill_opacity=1.0\n",
        "                        ).add_to(pol)\n",
        "\n",
        "\n",
        "    # 지하수 유동방향 지도\n",
        "    url=\"http://www.gims.go.kr/api/wms?KEY=rwKBcuRhkThP9tNcW%2F6NA2bMWnTefj8BXA8C1YAkEqBE9%2FzNldesNIA7Szu7AY1R\"\n",
        "    webms = WebMapService(url, version='1.3.0')\n",
        "    layer = '36'\n",
        "    wms = webms.contents[layer]\n",
        "    lon = (wms.boundingBox[0] + wms.boundingBox[2]) / 2.0\n",
        "    lat = (wms.boundingBox[1] + wms.boundingBox[3]) / 2.0\n",
        "\n",
        "    m_wms = folium.raster_layers.WmsTileLayer(url=url, fmt=\"image/png\", name=wms.title, transparent=True, layers=layer, \n",
        "                                              overlay=True, control=True, show=False)\n",
        "    m_wms.add_to(m)\n",
        "    \n",
        "    folium.LayerControl(collapse=False).add_to(m)\n",
        "    \n",
        "    result_map = \"map.html\"\n",
        "    m.save(result_map)\n",
        "    webbrowser.open(result_map, new=2)\n",
        "    \n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}